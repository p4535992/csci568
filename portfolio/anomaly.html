<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
  <title>Anomaly Detection</title>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>
<body>
<h1>Anomaly Detection</h1>
<h2>Introduction</h2>
<p>Anomalies are outliers in data. They could represent numerous different events. They may be the result of errors in data collection, or might be natural anamolies, representing a freak occurance. For example, maybe you did actually interview a 9-foot person while collecting data for a weight-loss study, or maybe the person conducting the study wrote their 6 upside down. Because errors during data collection is such a common cause for anamolies, one of the best steps to prevent them is to implement policies or checks that can catch them during the data collection stage. Unfortunately, as mentioned in an earlier section, you do not often get to collect your own data, and often the data you're mining was collected for another purpose. Regardless of it's source, the reality of data mining is that data sets will commonly contain anomalies, and it is the job of the miner to detect them. There are a few different ways to do this, and in this section I will talk about statistical approaches, clustering-based approaches, denisty-based approaches, and finally proximity-based approaches.</p>
<p>Anamolies are detected for many reasons. In some cases, such as network intrusion detection, the anomalies are the goal of the mining algorithm. In this case, data mining is used to find irregular activity on the network, whether it be an unusual load from a certain location, or acess from an odd or foriegn ip address. These unusual, or rare, cases are in fact anomalies. Another instance where anomalies are a good thing is with e-commerce or market-basket data. In these cases, an anomaly might represent an unusual amount of money spent by a particular customer. This could indicate a very good customer that you would want to detect in order to cater to his needs and make sure you maintain his business. In most cases, however, anomalies are bad because they can throw off calculations. For example, in K-Means clustering, they can pull the centroid of a cluster away from where it should actually be. Therefore, they usually want to be discovered so they can be removed from the dataset in order to obtain more accurate results. Regardless of the goal of anomaly detection, the following approaches are all useful means for discovering them.</p>
<h2>Statistical Anomaly Detection</h2>
<p>Statistical anomaly detection is based on Guassian distribution. Guassian, or normal, distribution forms a bell curve when graphed. It is defined by the following equation, where $\sigma$ is the standard deviation of the data set, $\sigma^{2}$ is the variance, $\mu$ is the mean or expected value, and $e$ is euler's number.</p>
<div class="equation">
\(f(x)=\frac{1}{\sqrt{2\pi^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)
</div>
<p>When $\mu = 0$ and $\sigma^2 = 1$, the distribution is called standard normal. Below is a graph showing the resulting bell curve from a few different distributions, including the standard normal in red.</p>
<img src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/500px-Normal_Distribution_PDF.svg.png" />
<p>As can be seen in the graph, in a Guassian distribution, most points are around the same area, and that is the area under the bell. In a normal distribution the bell is in the middle of the data, while in a skewed distirbution (such as the green line), the bell may be off to one side or the other. In either case, most of the data points are found around the center of the bell. The distance a point is away from the center of the bell can be determined by it's standard deviation. The center of the bell is $\mu$, which represents the mean of the data. This is also called the expected value, since it is the average of the data. Think of a game, with a maximum score of 5. If a player scored a 2 on the first round and 4 on the second round, and you were asked to guess how well they would do on the third round, how would you do it? What would the expected score be? The easiest way to approach this problem is to take the average of the player's previous scores, and predict he will score a 3 on the next round. This is why it is called the expected value. The amount a data point deviates from this expected value is called standard deviation, and is represented by a $\sigma$. Below is a graph that illustrates a standard normal distribution split by how many standard deviations the data points in each section of the curve are away from the mean.</p>
<img src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/500px-Standard_deviation_diagram.svg.png" />
<p>As you can see, about 68% of all the data points are within one standard deviation from the mean. About 95% of the data points are withing two standard deviations from the mean. Fnally, over 99% of the data is within three standard deviations from the mean. Statistically based anomaly detection uses this knowledge to discover outliers. A dataset can be standarized by taking the z-score of each point. A z-score is a measure of how many standard deviations a data point is away from the mean of the data. Any datapoint that has a z-score higher than 3 is an outlier, and likely to be an anomaly. As the z-score increases above 3, points become more obviously anomalous. A z-score is calculated using the following equation.</p>
<div class="equation">
\(z=\frac{x-\mu}{\sigma}\)
</div>
<p>Once z-scores are calculated, they can be graphed so that anomalies can more easily be seen. I used a statistical approach to discover anaomalies in the famous mushroom data set. I first divided the data up into two sets, edible mushrooms and poisonous mushrooms. I then found the z-scores for each attribute in each record, and graphed them using a box-plot graph. A box-plot is perfect for this application because it can be thought of as looking top down on a bell-curve where the box represents the bell, and items marked with a red "x" are numerous standard deviations away and therefore anomalous. The x-axis represents the attribute, and the y-axis is the number of standard deviations away from the mean, which is of course 0 standard deviations away from itself.</p>
<div class="visualization first">
  <h3>Edible Mushroom Anomalies</h3>
  <img src="images/edible_anamolies.png" />
</div>
<div class="visualization">
  <h3>Poisonous Mushroom Anomalies</h3>
  <img src="images/poisonous_anamolies.png" />
</div>
<p>In the graph for the poisonous mushrooms, attributes 6, 7, 17, and 18 all have data points that are more than 5 standard deviations away from the mean. While all of these are likely to be anamolies, the most noticeable are attributes 6 and 17, with clearly anamolous points at 15 and 20 standard deviations away from mean, respectively. Statistical anomaly detection is a quick and effective means to detect anamolies, and can be easily visualized in graphs like the one above.</p>
<h2>Clustering-Based Anomaly Detection</h2>

<h2>Density-Based Anomaly Detection</h2>

<h2>Proximity-Based Anomaly Detection</h2>
</body>
</html>